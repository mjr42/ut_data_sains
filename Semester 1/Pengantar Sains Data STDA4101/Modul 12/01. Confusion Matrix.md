---
tags:
  - materi_12_PSD
  - sains_data
---
## 01. Confusion Matrix

Confusion matrix biasanya digunakan untuk mengukur ketidakpastian dari hasil klasifikasi, baik klasifikasi terbimbing (supervised) maupun tidak terbimbing (unsupervised). Jumlah hasil klasifikasi yang benar dan salah kemudian dihitung untuk setiap kelas klasifikasi yang digunakan dalam analisis.

![[Screenshot 2024-10-26 at 20.55.52.png]]

Gambar 12.1 menunjukkan contoh tabel yang digunakan untuk meng-ukur hasil akhir ketidakpastian dari suatu proses klasifikasi. 

>Jika hasil uji dari data sebenarnya benar (aktual) dan hasil model klasifikasi (prediksi) juga benar, maka akan masuk ke kelas True Positive (TP), 

>sebaliknya jika hasil uji dari data sebenarnya benar, namun hasil model klasifikasi salah, maka akan masuk ke kelas False Negative (FN).

>Selanjutnya, jika hasil uji dari data aktual salah, namun pada hasil model prediksi dinyatakan benar, maka akan masuk ke kelas False Positive (FP).

Jika hasil uji dari data aktual salah, dan pada hasil model prediksi juga dinyatakan salah, maka akan masuk ke kelas True Negative (TN), 

dengan memiliki jumlah total TP, FN, FP, dan TN, kini kita dapat menghitung Sensitivity (Recall), Specificity, Precision, Negative Predictive Value (Error), dan Accuracy

#### 1. Presisi

Presisi adalah proporsi kelas yang diidentifikasi dengan benar, terhadap semua titik uji. Presisi akan menjawab pertanyaan "berapa banyak titik uji hutan yang berhasil diidentifikasi sebagai hutan secara presisi".

#### 2. Negative Predictive Value (Error)

Negative Predictive Value (Error) adalah proporsi kesalahan dalam klasifikasi, yang akan menjawab pertanyaan "berapa tingkat kesalahan klasifikasi".

#### 3. Akurasi

Akurasi adalah proporsi hasil yang benar secara umum dari sebuah kelas klasifikasi. Akurasi akan menjawab pertanyaan "berapa banyak titik uji hutan yang secara akurat diidentifikasi sebagai hutan dari seluruh titik uji".

#### 4. F1 Score

Lebih jauh kita juga dapat menghitung F1 skor, yaitu sebuah metode untuk mengukur performa klasifikasi yang lebih baik untuk distribusi kelas yang tidak merata dalam data uji. 

Sebagai contoh distribusi kelas yang tidak merata terkadang muncul dalam prediksi klasifikasi penggunaan lahan menggunakan data citra satelit, di mana sebagian besar hasil Klasifikasi adalah benar dan sebagian kecil yang salah.

- Fl skor dapat dihitung dengan persamaan
- ﻿﻿F1 skor = 2*(Sensitivity*Precision)/Sensitivity+Precision)

#### 5. Sensitivity

sensitivity (recall), yaitu tingkat positif yang sebenarnya, apa artinya? Jika menggunakan rumus TP/(TP+FN) sebagai contoh sensitivity pada kasus klasifikasi citra satelit, akan menjadi 30/(30+25) = 30/55 = 6/11. Dengan kata lain, 6 dari 11 titik klasifikasi hutan berhasil diidentifikasi dengan benar sebagai "hutan". 

Sensitivity (Recall) akan menjawab pertanyaan "dari semua titik uji hutan, berapa banyak yang benar diidentifikasi sebagai hutan". Sensitivity (Recall) disebut juga True Positive Rate (TPR).

#### 6. Specificity

Sementara itu apa arti dari specificity? Dengan menggunakan rumus TN/(TN+FP), akan memberikan informasi tingkat negatif yang sebenarnya.

Masih dengan contoh kasus kelas hutan dari klasifikasi citra satelit, 50/(50+5) = 50/55 = 10/11, artinya 10 dari 11 titik observasi yang bukan hutan berhasil diklasifikasi sebagai "bukan hutan". 

Specificity akan menjawab pertanyaan "dari semua titik uji bukan hutan, berapa banyak yang benar diidentifikasi sebagai bukan hutan". 1 - Specificity disebut juga False Positive Rate (FPR).

#### Perbedaannya

Cara paling mudah untuk mengingat perbedaan antara sensitivity (recall) dan specificity adalah dengan mengingat lampu taman. Jika lampu taman sangat sensitif, maka lampu akan menyala terlalu mudah, misal hanya jika ada daun jatuh dari pohon, maka lampu akan menyala. Jika ter-lalu spesifik, maka lampu taman tersebut hanya akan menyala jika ada orang berlalu tepat di depannya saja, atau mungkin tidak menyala jika malam tiba.

Sulit menemukan keseimbangan antara sensitivity (recall) dan speci-ficity hanya dengan menggunakan Confusion matrix, maka kita dapat menggunakan metode selanjutnya, yaitu Area under receiver operator curve (AUROC).

